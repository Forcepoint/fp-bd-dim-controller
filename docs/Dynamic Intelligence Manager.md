# Dynamic Intelligence Manager

## Overview
The Dynamic Intelligence Manager is a modular system by design to allow for easy extension of functionality and to be very flexible in terms of intelligence sources and consumers.

How this is achieved is through having a central controller which allows functional modules to register themselves and also their potential functionality, i.e. are they sources of intelligence or consumers of it, what endpoints they support etc.

There is no limit to the number of sources or consumers that can be added to the system.

## Technologies Used 
The system runs in docker as it allows for ease of installation and use and is extremely portable. It also makes use of docker networking to create private subnets for each of the follwing: internal (module to controller) communication, controller to database and UI module to controller. This gives some added security to the system.

The controller is written in Go, as are some of the functional modules. The UI module is written in Typescript using the Vue framework. The UI module uses Nginx to serve its files and also to. reverse proxy calls to the controller.
The controller also reverse proxys calls to the modules, which means that the controller has direct control over all traffic to and from modules. 

Persistence is through an instance of MariaDB which is spun up as part of the docker-compose for the controller.

## Authn/Authz
Authentication is a simple email/password combination but with a view to integrate with SSO services later down the line. Password is stored in a mariadb instance using bcrypt.

Authorization from the UI module and for all `/api` endpoints is done using a JWT, this is returned on login and included in the `x-access-token` for all calls from the UI.

Authorization between modules and the controller is done using a registration token that is generated by the controller on first run, this can be retrieved by hitting the `/api/keys` endpoint. As with all `/api` endpoints, you need to be logged in and have a valid JWT to retrieve this token.

This is valid for all `/internal` routes.
Before you start a module you need to add this token to the docker-compose of this module under the `INTERNAL_TOKEN` environment variable as it is required for the module to register itself with the controller.
This token is passed in the `x-internal-token` header of all requests.

There is a third type of Auth, which is used for modules that need to be pushed to by a service that can't store state, i.e. AWS lambdas.

For these modules we simply generate a URL with a token query param called `token` which is then displayed in the UI in the config section for that module, this URL can then be set in the external service and the module can then verify it is correct.

Due to the fact that this isn't using JWT or the internal token, another route prefix was added to support this functionality and that is `/ingress`. 

To utilise this you can simply set the `/run` method of the module to be `secure=false` inthe registration payload and the controller will automatically add it to the `/ingress` route.

## Module Communication
All communication for the system happens internally within the docker network using docker DNS name resolution, therefore the name given to the service is very important and must be consistent between the registration data and the docker-compose service name.

### Docker-Compose Network Setup
if you are adding a module to the system, you will need to join it to the private `module-net` that is used for modules to communicate to the controller and vice-versa. 
The network name gets prefixed with the name of the folder that you ran the controllers docker-compose in, so for example if we ran it in a folder called `compose-files` the name of the network would be `compose-files_module-net` and we should add the following to our modules docker-compose:  

```
...
    # add this to the service definition for the module
    networks:
      - compose-files_module-net

# Add this to the bottom of the file to tell docker-compose we are 
joining an external network
networks:
  compose-files_module-net:
    external: true
```

Now that this is done the module and controller are on the same network and communicate with each other.

## Endpoints
### Controller
In-depth endpoint information can be found here about the controller endpoints:
<Link to doc here>

### Modules
In-depth endpoint information can be found here about the module endpoints:
<Link to doc here>

## Module Development Guide
### Language 
Modules are language agnostic, they can be written in any language you feel comfortable with as long as it abides by the API contracts.
Module development for us is mostly in Go, due to ease of development and reusability.
### First Steps
1. In your project, create a top-level folder called config with a config.yml inside (if required), create a Readme describing what the module does and any special requirements, create a Dockerfile and a Docker-Compose file with the required environment variables.  

```
INTERNAL_TOKEN:
HOST_DOMAIN:
CONTROLLER_SVC_NAME: dem-controller
CONTROLLER_PORT: 8080
MODULE_SVC_NAME: <your_service_name>
LOCAL_PORT: 8080
```

2. Next you need to register your module with the controller and the way to do that is to `POST` the Module Metadata to the `/internal/register` endpoint. The structure for the expected Module Metadata can be found under Controller in the Endpoints section. Once you have defined the metadata you need to `POST` it to the registration endpoint, since this is an internal endpoint you need to include the registration token in the `x-internal-token` header of your request. If this request is successful you will get a `202` status returned and you will see an info level log in the UI log page.

3. Next we need to define the config for our module, this is done using JSON served to the UI module that creates the UI dynamically depending on what we specify in the module. How this works can be seen in Modules in the endpoint section. This is where we would add required URLs, Passwords, Usernames, Ports etc. required for the modules external functionality (pulling or pushing from/to intelligence sources). If an ingress module requires a URL query param based auth set up, you would dynamically create and expose the URL here.

4. If you wish for the logs from your module to be shown in the UI logs section, you can create a logging hook for logrus that will trigger on specified levels and you can write a function to push them to a logging endpoint on the controller at `/internal/logevents`, since this is a `/internal` route, it requires the `x-internal-token` header to be set. The structure of the log event can be seen in the module document.
5. Next up is the functionality of your module, what it actually does. This is the functionality that will be trigered by the `/run` endpoint of your module. This implementation is up to you, but for `egress` modules this endpoint is required to accept `POST` requests and accept data in the form of:  

```
type ProcessedItem struct {
	Source        string `json:"source"`
	ServiceName   string `json:"service_name"`
	Type          string `json:"type"`
	Value         string `json:"value"`
	UpdateBatchId uint   `json:"batch_number"`
}
```
6. This is the format of the data that will be pushed to the module from the controller for dissemination to the intelligence consumers. For `ingress` modules, this is the format that they should push to the controller.

7. If the module you are creating is an `ingress` module, in that it takes data from an intelligence source, processes it and pushes it to the controler for consumption, it needs to do so via a `POST` to the `/internal/queue` endpoint, the above structure is what is expected (`UpdateBatchId` can be ignored). As with all `/internal` endpoints, the `x-internal-token` header needs to be set.

